{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow,Flow\n",
    "from google.auth.transport.requests import Request\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dates\n",
    "year = datetime.today().strftime(\"%Y\")\n",
    "start = datetime(2020,9,8)\n",
    "week = str(round(((datetime.today() - start).days+2)/7))\n",
    "\n",
    "# add option to pass week\n",
    "# url parser\n",
    "def crawler(url,week_num=week):\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# pull soup from fivethirtyeight and vegasinsider\n",
    "fte_url = 'https://projects.fivethirtyeight.com/'+year+'-nfl-predictions/games/'\n",
    "fte_soup = crawler(fte_url)\n",
    "vegas_url = 'https://www.vegasinsider.com/nfl/matchups/matchups.cfm/week/'+week+'/season/'+year\n",
    "vegas_soup = crawler(vegas_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to match team names w/city names\n",
    "def team_match(x):\n",
    "    if 'jets' in x.lower():\n",
    "        return 'Jets'\n",
    "    if 'indiana' in x.lower():\n",
    "        return 'Colts'\n",
    "    if 'denver'in x.lower():\n",
    "        return 'Broncos'\n",
    "    if 'chica'in x.lower():\n",
    "        return 'Bears'\n",
    "    if 'orlean'in x.lower():\n",
    "        return 'Saints'\n",
    "    if 'arizon' in x.lower():\n",
    "        return 'Cardinals'\n",
    "    if 'carolin' in x.lower():\n",
    "        return 'Panthers'\n",
    "    if 'detroit' in x.lower():\n",
    "        return 'Lions'\n",
    "    if 'cinci' in x.lower():\n",
    "        return 'Bengals'\n",
    "    if 'jackson'in x.lower():\n",
    "        return 'Jaguars'\n",
    "    if 'dallas' in x.lower():\n",
    "        return 'Cowboys'\n",
    "    if 'cleve' in x.lower():\n",
    "        return 'Browns'\n",
    "    if 'houst'in x.lower():\n",
    "        return 'Texans'\n",
    "    if 'minne' in x.lower():\n",
    "        return 'Vikings'\n",
    "    if 'seat' in x.lower():\n",
    "        return 'Seahwaks'\n",
    "    if 'miami' in x.lower():\n",
    "        return 'Dolphins'\n",
    "    if 'tampa' in x.lower():\n",
    "        return 'Buccaneers'\n",
    "    if 'charg' in x.lower():\n",
    "        return 'Chargers'\n",
    "    if 'pitt' in x.lower():\n",
    "        return 'Steelers'\n",
    "    if 'tenn' in x.lower():\n",
    "        return 'Titans'\n",
    "    if 'balti' in x.lower():\n",
    "        return 'Ravens'\n",
    "    if 'washing' in x.lower():\n",
    "        return 'Washington'\n",
    "    if 'rams' in x.lower():\n",
    "        return 'Rams'\n",
    "    if 'giant' in x.lower():\n",
    "        return 'Giants'\n",
    "    if 'kansas' in x.lower():\n",
    "        return 'Chiefs'\n",
    "    if 'england' in x.lower():\n",
    "        return 'Patriots'\n",
    "    if 'buff' in x.lower():\n",
    "        return \"Bills\"\n",
    "    if 'vegas' in x.lower():\n",
    "        return 'Raiders'\n",
    "    if 'franc' in x.lower():\n",
    "        return '49ers'\n",
    "    if 'phila' in x.lower():\n",
    "        return 'Eagles'\n",
    "    if 'green' in x.lower():\n",
    "        return 'Packers'\n",
    "    if 'atlan' in x.lower():\n",
    "        return 'Falcons'\n",
    "    else:\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titans +3.5 vs Bills is the top play with a 4.5pt difference\n",
      "Jets -7.0 vs Cardinals is the number 2 play with a 3.5pt difference\n",
      "Jaguars -6.5 vs Texans is the number 3 play with a 2.5pt difference\n",
      "Titans +1.0 vs Bills is the number 4 play with a 2.0pt difference\n"
     ]
    }
   ],
   "source": [
    "# generate elo spreads\n",
    "elo_favorites = []\n",
    "elo_underdogs = []\n",
    "elo_spreads = []\n",
    "current_week_tag_list = fte_soup.find(\"div\", class_=\"days\").find_all(\"tr\")\n",
    "\n",
    "for tag in current_week_tag_list:\n",
    "    if tag.contents[0].get('class') != ['th', 'time']:\n",
    "        if len(tag.contents[2].text) > 1:\n",
    "            elo_favorites.append(tag.contents[1].text.strip())   # favorite\n",
    "            try:\n",
    "                elo_spreads.append(float(tag.contents[2].text[2:]))    # favorite spread\n",
    "            except:\n",
    "                elo_spreads.append(float(0))        # PK\n",
    "        else:\n",
    "            elo_underdogs.append(tag.contents[1].text.strip())    # dog\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "elo_tuple = list(zip(elo_favorites, elo_underdogs, elo_spreads))\n",
    "\n",
    "\n",
    "# generate vegas spreads\n",
    "vegas_favorites = []\n",
    "vegas_underdogs = []\n",
    "vegas_spreads = []\n",
    "\n",
    "current_week_game_tags = vegas_soup.find_all(\"div\",class_='SLTables1')[1].find_all(\"div\",class_='SLTables1')\n",
    "\n",
    "for game_tag in current_week_game_tags:\n",
    "    for row_tag in game_tag.find_all(\"tr\")[4:6]:\n",
    "        if '-' in row_tag.find_all('td')[4].text:\n",
    "            vegas_favorites.append(team_match(row_tag.find('a').text))        # favorite\n",
    "            vegas_spreads.append(float(row_tag.find_all('td')[4].text[1:]))   # favorite spread\n",
    "        elif 'PK' in row_tag.find_all('td')[4].text:\n",
    "            vegas_favorites.append(team_match(row_tag.find('a').text))\n",
    "            vegas_spreads.append(float(0))                                   # PK\n",
    "        else:\n",
    "            vegas_underdogs.append(team_match(row_tag.find('a').text))       # dog\n",
    "\n",
    "vegas_tuple = list(zip(vegas_favorites,vegas_underdogs,vegas_spreads))\n",
    "\n",
    "\n",
    "# compare spreads and select picks\n",
    "teams_to_bet = []\n",
    "elo_to_vegas_abs_diffs = []\n",
    "\n",
    "for elo_tup in elo_tuple:\n",
    "    for vegas_tup in vegas_tuple:\n",
    "        if elo_tup[0] not in vegas_tup:\n",
    "            pass\n",
    "        elif elo_tup[0] == vegas_tup[0] and elo_tup[1] == vegas_tup[1]:\n",
    "            elo_to_vegas_diff = elo_tup[2] - vegas_tup[2]\n",
    "            if elo_to_vegas_diff <= 0:\n",
    "                teams_to_bet.append(elo_tup[1]+' '+str(vegas_tup[2]*-1)+' vs '+ vegas_tup[0])   # bet favorite\n",
    "            else:\n",
    "                teams_to_bet.append(elo_tup[0]+' '+str(vegas_tup[2])+' vs '+ vegas_tup[1])      # TBD\n",
    "            elo_to_vegas_abs_diffs.append(abs(elo_to_vegas_diff))\n",
    "        elif elo_tup[0] == vegas_tup[1] and elo_tup[1] == vegas_tup[0]:\n",
    "            elo_to_vegas_diff = elo_tup[2] + vegas_tup[2]\n",
    "            teams_to_bet.append(elo_tup[0]+' +'+str(vegas_tup[2])+' vs '+ vegas_tup[0])         # bet dog\n",
    "            elo_to_vegas_abs_diffs.append(abs(elo_to_vegas_diff))\n",
    "\n",
    "plays = list(zip(teams_to_bet,elo_to_vegas_abs_diffs))\n",
    "plays.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "\n",
    "for i in range(len(plays)):\n",
    "    if plays[i][1] > 1.5:\n",
    "        if i==0 and plays[0][1]>plays[1][1]:\n",
    "            print('{} is the top play with a {}pt difference'.format(plays[i][0],plays[i][1]), sep='\\n')\n",
    "        else:\n",
    "            print('{} is the number {} play with a {}pt difference'.format(plays[i][0],\n",
    "                                                                        i+1,plays[i][1]), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff</th>\n",
       "      <th>dog</th>\n",
       "      <th>favorite</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>Bills</td>\n",
       "      <td>Titans</td>\n",
       "      <td>+3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>Jets</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Texans</td>\n",
       "      <td>Jaguars</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Bills</td>\n",
       "      <td>Titans</td>\n",
       "      <td>+1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diff        dog favorite spread\n",
       "0   4.5      Bills   Titans   +3.5\n",
       "1   3.5  Cardinals     Jets   -7.0\n",
       "2   2.5     Texans  Jaguars   -6.5\n",
       "3   2.0      Bills   Titans   +1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record data\n",
    "df = pd.DataFrame()\n",
    "for i in plays:\n",
    "    if i[1] > 1.5:\n",
    "        row= {}\n",
    "        row['favorite'] = i[0].split()[0]\n",
    "        row['spread'] = i[0].split()[1]\n",
    "        row['dog'] = i[0].split()[3]\n",
    "        row['diff'] = i[1]\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to g-sheet\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "sheet_id='1d2G32M8mn2Va-JaVAwV1JfwXjhJMPJbb-1UYOXjKTC4'\n",
    "data_range='Sheet1!A1:D'\n",
    "\n",
    "# setup credentials\n",
    "creds = None\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('/Users/ccaspar/downloads/credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "# sheets API\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "sheet = service.spreadsheets()\n",
    "result = sheet.values().get(spreadsheetId=sheet_id, range=data_range).execute()\n",
    "values = result.get('values', [])\n",
    "df = pd.DataFrame(values, columns=values[0])[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to load prior data in separate df\n",
    "# need to add new data to prior data\n",
    "# need to send complete data back into gsheet\n",
    "# add week column for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'ndarray' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4b4fcada0deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalueInputOption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RAW'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     body=dict(majorDimension='ROWS', values=df.values)).execute()\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/googleapiclient/discovery.py\u001b[0m in \u001b[0;36mmethod\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         headers, params, query, body = model.request(\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_path_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_query_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         )\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/googleapiclient/model.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, headers, path_params, query_params, body_value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbody_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mbody_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/googleapiclient/model.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, body_value)\u001b[0m\n\u001b[1;32m    273\u001b[0m         ):\n\u001b[1;32m    274\u001b[0m             \u001b[0mbody_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbody_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'ndarray' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# need to make df into dict\n",
    "response_date = service.spreadsheets().values().update(\n",
    "    spreadsheetId=sheet_id,\n",
    "    valueInputOption='RAW',\n",
    "    range=data_range,\n",
    "    body=dict(majorDimension='ROWS', values=df.values)).execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
